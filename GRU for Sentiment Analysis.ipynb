{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import re\n",
    "import nltk\n",
    "from nltk.tokenize import sent_tokenize,word_tokenize\n",
    "\n",
    "from collections import Counter  \n",
    "import numpy as np\n",
    "import string \n",
    "#import spacy\n",
    "from nltk.stem import PorterStemmer\n",
    "from collections import Counter  \n",
    "from nltk.corpus import stopwords\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "25000"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#load data \n",
    "\n",
    "def get_data(path):\n",
    "    files=os.listdir(path)\n",
    "    data=[]\n",
    "    for fsub in files:\n",
    "        f = open(path+\"/\"+fsub,\"r\",encoding='UTF-8').read()\n",
    "        data.append(f)\n",
    "    return data\n",
    "\n",
    "#path='/Users/dl/Documents/RIT related/aclImdb/train/'\n",
    "#path2='/Users/dl/Documents/RIT related/aclImdb/test/'\n",
    "\n",
    "path = \"C:/Users/wangx/IMDB/train/\"\n",
    "path2 = \"C:/Users/wangx/IMDB/test/\"\n",
    "\n",
    "train_pos=get_data(path+'pos')   # 12500  list\n",
    "train_neg=get_data(path+'neg')   # 12500\n",
    "train_data=train_pos+train_neg   # 25000\n",
    "test_pos=get_data(path2+'pos')   # 12500  list\n",
    "test_neg=get_data(path2+'neg')\n",
    "test_data=test_pos+test_neg      # 25000\n",
    "len(test_data)\n",
    "#train_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "30202"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# build vocab with frequency\n",
    "from nltk.corpus import stopwords\n",
    "stop_words = set(stopwords.words('english'))\n",
    "\n",
    "def vocabulary(data):\n",
    "    total=[]\n",
    "    ps=PorterStemmer() \n",
    "    for s in data:\n",
    "        word=word_tokenize(s)\n",
    "        for w in word:\n",
    "            if w.lower().isalpha() and w.lower() not in stop_words:\n",
    "                total.append(ps.stem(w.lower()))   \n",
    "\n",
    "    vocab=Counter(total)\n",
    "    # Removing the words that only appear once\n",
    "    vocab = {k:v for k,v in vocab.items() if v>1}\n",
    "    # Sorting the words according to the number of appearances, with the most common word being first\n",
    "    vocab = sorted(vocab, key=vocab.get, reverse=True)\n",
    "    vocab = ['_UNK'] + vocab\n",
    "    word2idx = {o:i for i,o in enumerate(vocab)}\n",
    "    idx2word = {i:o for i,o in enumerate(vocab)}\n",
    "    return word2idx,idx2word\n",
    "                \n",
    "word2idx,idx2word=vocabulary(train_data)\n",
    "#len(vocab)  #48448\n",
    "len(word2idx)  #30202"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def data_proprocessing(data,word2idx):\n",
    "    dataclean=[]\n",
    "    ps=PorterStemmer() \n",
    "    for s in data:\n",
    "        sen=[]\n",
    "        word=word_tokenize(s)\n",
    "        for w in word:\n",
    "            if w.lower().isalpha() and w.lower() not in stop_words:\n",
    "                sen.append(ps.stem(w.lower()))            \n",
    "        \n",
    "        #text_as_int = [vocab[c] for c in sen]  \n",
    "        text_as_int=[word2idx[word] if word in word2idx else 0 for word in sen]\n",
    "        if len(sen)>400:\n",
    "            data_list=text_as_int[0:400]\n",
    "        else:\n",
    "            l=400-len(sen)\n",
    "            data_list=[0]*l+text_as_int                  \n",
    "        dataclean.append(data_list)    \n",
    "    return np.array(dataclean)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "25000"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_x=data_proprocessing(train_data,word2idx)\n",
    "test_x=data_proprocessing(test_data,word2idx)\n",
    "#len(test_x)  # 25000\n",
    "\n",
    "N=len(train_pos)\n",
    "train_y=np.vstack((np.ones((N,1)),np.zeros((N,1))))\n",
    "test_y=np.vstack((np.ones((N,1)),np.zeros((N,1))))\n",
    "len(train_x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torchvision\n",
    "from torch.utils.data import TensorDataset, DataLoader\n",
    "import torch.nn as nn\n",
    "import matplotlib.pyplot as plt\n",
    "from torch.optim import lr_scheduler\n",
    "\n",
    "train_data=TensorDataset(torch.from_numpy(train_x),torch.from_numpy(train_y))\n",
    "test_data = TensorDataset(torch.from_numpy(test_x), torch.from_numpy(test_y))\n",
    "batch_size =50\n",
    "train_loader = DataLoader(train_data, shuffle=True, batch_size=batch_size)\n",
    "test_loader = DataLoader(test_data, shuffle=True, batch_size=batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "device(type='cuda')"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "is_cuda = torch.cuda.is_available()\n",
    "\n",
    "# If we have a GPU available, we'll set our device to GPU. We'll use this device variable later in our code.\n",
    "if is_cuda:\n",
    "    device = torch.device(\"cuda\")\n",
    "else:\n",
    "    device = torch.device(\"cpu\")\n",
    "device\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# design GRU model \n",
    "import torch.nn as nn\n",
    "\n",
    "class GRUSentiment(nn.Module):\n",
    "    def __init__(self,vocab_size, output_size, embedding_dim, hidden_dim, n_layers,drop_prob=0.2):   \n",
    "        super(GRUSentiment, self).__init__()\n",
    "        self.output_size = output_size\n",
    "        self.n_layers = n_layers\n",
    "        self.hidden_dim = hidden_dim\n",
    "        \n",
    "        self.embedding = nn.Embedding(vocab_size, embedding_dim)\n",
    "        self.gru = nn.GRU(embedding_dim, hidden_dim, n_layers, batch_first=True)\n",
    "        self.dropout = nn.Dropout(drop_prob)\n",
    "        self.fc = nn.Linear(hidden_dim, output_size)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        batch_size = x.size(0)\n",
    "        x = x.long()\n",
    "        embeds = self.embedding(x)\n",
    "        gru_out, hidden = self.gru(embeds)\n",
    "        out=self.dropout(gru_out)\n",
    "        \n",
    "        out = self.fc(out)        \n",
    "        out = out.view(batch_size, -1)\n",
    "        #out = out[:,-1]  # get the last one\n",
    "        out=out[:,-1].view(-1,1)\n",
    "        return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GRUSentiment(\n",
       "  (embedding): Embedding(30202, 400)\n",
       "  (gru): GRU(400, 256, batch_first=True)\n",
       "  (dropout): Dropout(p=0.2, inplace=False)\n",
       "  (fc): Linear(in_features=256, out_features=1, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vocab_size =  len(word2idx) \n",
    "output_size = 1\n",
    "embedding_dim = 400\n",
    "hidden_dim = 256\n",
    "n_layers = 1\n",
    "\n",
    "model1 = GRUSentiment(vocab_size, output_size, embedding_dim, hidden_dim, n_layers)\n",
    "model1.to(device)\n",
    "\n",
    "lr=1e-4\n",
    "#criterion = nn.BCELoss()\n",
    "criterion = nn.BCEWithLogitsLoss()\n",
    "optimizer = torch.optim.Adam(model1.parameters(), lr=lr)\n",
    "model1.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(0.6582, device='cuda:0', dtype=torch.float64,\n",
       "       grad_fn=<BinaryCrossEntropyWithLogitsBackward>)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model1.train() \n",
    "for inputs, labels in train_loader:\n",
    "                \n",
    "        inputs, labels = inputs.to(device), labels.to(device)\n",
    "        #model.zero_grad()\n",
    "        optimizer.zero_grad()        \n",
    "        output= model1(inputs)\n",
    "        loss = criterion(output, labels)\n",
    "        loss.backward()\n",
    "loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([200, 1])"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def binary_accuracy(preds, y):\n",
    "    \"\"\"\n",
    "    Returns accuracy per batch, i.e. if you get 8/10 right, this returns 0.8, NOT 8\n",
    "    \"\"\"\n",
    "\n",
    "    #round predictions to the closest integer\n",
    "    rounded_preds = torch.round(torch.sigmoid(preds))\n",
    "    correct = (rounded_preds == y).float() #convert into float for division \n",
    "    #acc = correct.sum() / len(correct)\n",
    "    acc = correct.sum()\n",
    "    return acc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate(model1, dataset, criterion):    \n",
    "    epoch_loss = 0\n",
    "    epoch_acc = 0\n",
    "    model1.eval()    \n",
    "    N=25000\n",
    "    with torch.no_grad():    \n",
    "        for data, label in dataset:\n",
    "            data, label = data.to(device), label.to(device)\n",
    "            pred = model1(data)            \n",
    "            loss = criterion(pred, label)           \n",
    "            acc = binary_accuracy(pred.squeeze(), label.squeeze())\n",
    "            \n",
    "            epoch_loss += loss.item()\n",
    "            epoch_acc += acc.item()        \n",
    "    return epoch_loss / N, epoch_acc /N"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch Loss: 0.010110035347163713 epoch Acc: 0.75396 testloss: 0.00851616707714721 test_acc 0.81264\n",
      "epoch Loss: 0.006123943786484509 epoch Acc: 0.8756 testloss: 0.00699617518677562 test_acc 0.85132\n",
      "epoch Loss: 0.003884648330975434 epoch Acc: 0.92752 testloss: 0.00742989704023615 test_acc 0.84976\n",
      "epoch Loss: 0.0021795739101056755 epoch Acc: 0.9632 testloss: 0.008253110048546187 test_acc 0.85856\n",
      "epoch Loss: 0.0011868886907961953 epoch Acc: 0.979 testloss: 0.009741987888377119 test_acc 0.85088\n",
      "epoch Loss: 0.0005742287262294822 epoch Acc: 0.99004 testloss: 0.011744406331599205 test_acc 0.85536\n",
      "epoch Loss: 0.0004290051630245658 epoch Acc: 0.99356 testloss: 0.013284818412529289 test_acc 0.8558\n",
      "epoch Loss: 0.0004872762547648221 epoch Acc: 0.99184 testloss: 0.013618180030265515 test_acc 0.85364\n",
      "epoch Loss: 0.00025799657296335284 epoch Acc: 0.996 testloss: 0.01430205151439855 test_acc 0.8498\n",
      "epoch Loss: 0.00011545907438338615 epoch Acc: 0.99852 testloss: 0.015496718770280034 test_acc 0.85528\n",
      "epoch Loss: 0.0003695092366900773 epoch Acc: 0.99404 testloss: 0.014229978973300285 test_acc 0.85004\n",
      "epoch Loss: 0.0002892092205657953 epoch Acc: 0.99492 testloss: 0.014948692918587737 test_acc 0.84872\n",
      "epoch Loss: 0.0002827803579423138 epoch Acc: 0.99572 testloss: 0.01469587175364119 test_acc 0.84992\n",
      "epoch Loss: 0.00026650953838330084 epoch Acc: 0.99572 testloss: 0.018725964588334903 test_acc 0.84388\n",
      "epoch Loss: 0.00012368189109904476 epoch Acc: 0.99784 testloss: 0.017683643016454146 test_acc 0.85508\n",
      "epoch Loss: 0.00010601121441191239 epoch Acc: 0.9984 testloss: 0.018348535891676832 test_acc 0.85404\n",
      "epoch Loss: 0.0001975279552864847 epoch Acc: 0.99692 testloss: 0.01782750033851131 test_acc 0.852\n",
      "epoch Loss: 0.00011669143162317386 epoch Acc: 0.99824 testloss: 0.018558054304303274 test_acc 0.85244\n",
      "epoch Loss: 0.00015948550440849103 epoch Acc: 0.99756 testloss: 0.018555763859905962 test_acc 0.84512\n",
      "epoch Loss: 0.0001970537659925563 epoch Acc: 0.99668 testloss: 0.019438888316120725 test_acc 0.8498\n",
      "epoch Loss: 0.00014442958667783759 epoch Acc: 0.99816 testloss: 0.01907605396271673 test_acc 0.85156\n",
      "epoch Loss: 5.898888403219126e-05 epoch Acc: 0.99892 testloss: 0.020154656975457878 test_acc 0.84944\n",
      "epoch Loss: 8.880128212548226e-05 epoch Acc: 0.99876 testloss: 0.020008859069456663 test_acc 0.84576\n",
      "epoch Loss: 0.00012631725319004153 epoch Acc: 0.99804 testloss: 0.019277943952420235 test_acc 0.84956\n",
      "epoch Loss: 8.272716766973845e-05 epoch Acc: 0.99864 testloss: 0.02007526982417044 test_acc 0.8508\n",
      "epoch Loss: 2.5036187092311196e-05 epoch Acc: 0.99972 testloss: 0.022127249244754798 test_acc 0.84612\n",
      "epoch Loss: 8.862170400138376e-05 epoch Acc: 0.99876 testloss: 0.02251307851493391 test_acc 0.84636\n",
      "epoch Loss: 0.0001170632416775985 epoch Acc: 0.99808 testloss: 0.02138949698957115 test_acc 0.847\n",
      "epoch Loss: 6.480867028646989e-05 epoch Acc: 0.99884 testloss: 0.02243194628216439 test_acc 0.85012\n",
      "epoch Loss: 5.228043296896811e-05 epoch Acc: 0.99932 testloss: 0.02417196554346949 test_acc 0.83796\n"
     ]
    }
   ],
   "source": [
    "def fitModel(epochs,model,criterion,optimizer,train_loader,test_loader,N):\n",
    "    clip =5\n",
    "    trainAcc=[]\n",
    "    testAcc=[]\n",
    "    #model1.train()\n",
    "    for i in range(epochs):\n",
    "        epoch_loss = 0\n",
    "        epoch_acc = 0\n",
    "\n",
    "        test_loss=0\n",
    "        test_acc=0\n",
    "\n",
    "        model1.train() \n",
    "        for inputs, labels in train_loader:\n",
    "\n",
    "            inputs, labels = inputs.to(device), labels.to(device)\n",
    "            #model.zero_grad()\n",
    "            optimizer.zero_grad()        \n",
    "            output= model1(inputs)\n",
    "            loss = criterion(output, labels)\n",
    "            loss.backward()\n",
    "            acc = binary_accuracy(output.squeeze(), labels.squeeze())\n",
    "            nn.utils.clip_grad_norm_(model1.parameters(), clip)\n",
    "            optimizer.step()\n",
    "\n",
    "            epoch_loss += loss.item()\n",
    "            epoch_acc += acc.item()\n",
    "\n",
    "        test_loss, test_acc =evaluate(model1, test_loader, criterion)          \n",
    "        print(\"epoch Loss:\",epoch_loss/N, \"epoch Acc:\",epoch_acc/N, \"testloss:\",test_loss, \"test_acc\",test_acc)\n",
    "        trainAcc.append(epoch_acc/N)\n",
    "        testAcc.append(test_acc)\n",
    "    return trainAcc,testAcc\n",
    "\n",
    "lr=1e-3\n",
    "#criterion = nn.BCELoss()\n",
    "criterion = nn.BCEWithLogitsLoss()\n",
    "optimizer = torch.optim.Adam(model1.parameters(), lr=lr)\n",
    "model1.eval()\n",
    "N=len(train_data)\n",
    "trainAcc,testAcc=fitModel(30,model1,criterion,optimizer,train_loader,test_loader,N)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.75396, 0.8756, 0.92752, 0.9632, 0.979, 0.99004, 0.99356, 0.99184, 0.996, 0.99852, 0.99404, 0.99492, 0.99572, 0.99572, 0.99784, 0.9984, 0.99692, 0.99824, 0.99756, 0.99668, 0.99816, 0.99892, 0.99876, 0.99804, 0.99864, 0.99972, 0.99876, 0.99808, 0.99884, 0.99932] [0.81264, 0.85132, 0.84976, 0.85856, 0.85088, 0.85536, 0.8558, 0.85364, 0.8498, 0.85528, 0.85004, 0.84872, 0.84992, 0.84388, 0.85508, 0.85404, 0.852, 0.85244, 0.84512, 0.8498, 0.85156, 0.84944, 0.84576, 0.84956, 0.8508, 0.84612, 0.84636, 0.847, 0.85012, 0.83796]\n"
     ]
    }
   ],
   "source": [
    "print(trainAcc,testAcc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Text(0.5, 1.0, 'GRU Test Acc Report')"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(testAcc,'-')\n",
    "plt.ylim([0,1])\n",
    "plt.xlabel(\"Epoch\")\n",
    "plt.ylabel(\"Accuracy\")\n",
    "plt.title(\"GRU Test Acc Report\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}

{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import re\n",
    "import nltk\n",
    "from nltk.tokenize import sent_tokenize,word_tokenize\n",
    "\n",
    "from collections import Counter  \n",
    "import numpy as np\n",
    "import string \n",
    "import spacy\n",
    "from nltk.stem import PorterStemmer\n",
    "from collections import Counter  \n",
    "from nltk.corpus import stopwords"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "25000"
      ]
     },
     "execution_count": 130,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#load data \n",
    "\n",
    "def get_data(path):\n",
    "    files=os.listdir(path)\n",
    "    data=[]\n",
    "    for fsub in files:\n",
    "        f = open(path+\"/\"+fsub,\"r\",encoding='UTF-8').read()\n",
    "        data.append(f)\n",
    "    return data\n",
    "\n",
    "#path='/Users/dl/Documents/RIT related/aclImdb/train/'\n",
    "#path2='/Users/dl/Documents/RIT related/aclImdb/test/'\n",
    "\n",
    "path = \"C:/Users/wangx/IMDB/train/\"\n",
    "path2 = \"C:/Users/wangx/IMDB/test/\"\n",
    "\n",
    "train_pos=get_data(path+'pos')   # 12500  list\n",
    "train_neg=get_data(path+'neg')   # 12500\n",
    "train_data=train_pos+train_neg   # 25000\n",
    "test_pos=get_data(path2+'pos')   # 12500  list\n",
    "test_neg=get_data(path2+'neg')\n",
    "test_data=test_pos+test_neg      # 25000\n",
    "len(test_data)\n",
    "#train_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "30202"
      ]
     },
     "execution_count": 131,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# build vocab with frequency\n",
    "from nltk.corpus import stopwords\n",
    "stop_words = set(stopwords.words('english'))\n",
    "\n",
    "def vocabulary(data):\n",
    "    total=[]\n",
    "    ps=PorterStemmer() \n",
    "    for s in data:\n",
    "        word=word_tokenize(s)\n",
    "        for w in word:\n",
    "            if w.lower().isalpha() and w.lower() not in stop_words:\n",
    "                total.append(ps.stem(w.lower()))   \n",
    "\n",
    "    vocab=Counter(total)\n",
    "    # Removing the words that only appear once\n",
    "    vocab = {k:v for k,v in vocab.items() if v>1}\n",
    "    # Sorting the words according to the number of appearances, with the most common word being first\n",
    "    vocab = sorted(vocab, key=vocab.get, reverse=True)\n",
    "    vocab = ['_UNK'] + vocab\n",
    "    word2idx = {o:i for i,o in enumerate(vocab)}\n",
    "    idx2word = {i:o for i,o in enumerate(vocab)}\n",
    "    return word2idx,idx2word\n",
    "                \n",
    "word2idx,idx2word=vocabulary(train_data)\n",
    "#len(vocab)  #48448\n",
    "len(word2idx)  #30202"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {},
   "outputs": [],
   "source": [
    "# proprocessing data to fix length 400\n",
    "\n",
    "def data_proprocessing(data,word2idx):\n",
    "    dataclean=[]\n",
    "    ps=PorterStemmer() \n",
    "    for s in data:\n",
    "        sen=[]\n",
    "        word=word_tokenize(s)\n",
    "        for w in word:\n",
    "            if w.lower().isalpha() and w.lower() not in stop_words:\n",
    "                sen.append(ps.stem(w.lower()))            \n",
    "        \n",
    "        #text_as_int = [vocab[c] for c in sen]  \n",
    "        text_as_int=[word2idx[word] if word in word2idx else 0 for word in sen]\n",
    "        if len(sen)>400:\n",
    "            data_list=text_as_int[0:400]\n",
    "        else:\n",
    "            l=400-len(sen)\n",
    "            data_list=[0]*l+text_as_int                  \n",
    "        dataclean.append(data_list)    \n",
    "    return np.array(dataclean)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "25000"
      ]
     },
     "execution_count": 133,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_x=data_proprocessing(train_data,word2idx)\n",
    "test_x=data_proprocessing(test_data,word2idx)\n",
    "#len(test_x)  # 25000\n",
    "\n",
    "N=len(train_pos)\n",
    "train_y=np.vstack((np.ones((N,1)),np.zeros((N,1))))\n",
    "test_y=np.vstack((np.ones((N,1)),np.zeros((N,1))))\n",
    "len(train_x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 185,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torchvision\n",
    "from torch.utils.data import TensorDataset, DataLoader\n",
    "import torch.nn as nn\n",
    "import matplotlib.pyplot as plt\n",
    "from torch.optim import lr_scheduler\n",
    "\n",
    "train_data=TensorDataset(torch.from_numpy(train_x),torch.from_numpy(train_y))\n",
    "#train_data=TensorDataset(torch.from_numpy(train_x),torch.from_numpy(train_y))\n",
    "\n",
    "test_data = TensorDataset(torch.from_numpy(test_x), torch.from_numpy(test_y))\n",
    "batch_size =25\n",
    "train_loader = DataLoader(train_data, shuffle=True, batch_size=batch_size)\n",
    "test_loader = DataLoader(test_data, shuffle=True, batch_size=batch_size)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 186,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 186,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# torch.cuda.is_available() checks and returns a Boolean True if a GPU is available, else it'll return False\n",
    "\n",
    "device = torch.cuda.current_device() if torch.cuda.is_available() else 'cpu'\n",
    "device "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 187,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MLP(nn.Module):\n",
    "    def __init__(self,input_dim,hidden1_size,num_class):\n",
    "        super(MLP,self).__init__()\n",
    "        self.fc1 = nn.Linear(input_dim,hidden1_size)\n",
    "        self.relu= nn.ReLU()\n",
    "        self.fc2 = nn.Linear(hidden1_size,num_class)\n",
    "        \n",
    "        \n",
    "    def forward(self,x):\n",
    "        out = self.fc1(x)\n",
    "        out = self.relu(out)\n",
    "        out = self.fc2(out)\n",
    "        return out\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 244,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "MLP(\n",
       "  (fc1): Linear(in_features=400, out_features=256, bias=True)\n",
       "  (relu): ReLU()\n",
       "  (fc2): Linear(in_features=256, out_features=1, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 244,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "model= MLP(400,256,1)\n",
    "model.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 245,
   "metadata": {},
   "outputs": [],
   "source": [
    "model= model.to(device)\n",
    "\n",
    "# Loss and optimizer\n",
    "criterion =nn.BCEWithLogitsLoss()\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=1e-3)  \n",
    "\n",
    "# Train the model\n",
    "total_step= len(train_loader)\n",
    "\n",
    "                             \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 246,
   "metadata": {},
   "outputs": [],
   "source": [
    "def binary_accuracy(preds, y):\n",
    "    \"\"\"\n",
    "    Returns accuracy per batch, i.e. if you get 8/10 right, this returns 0.8, NOT 8\n",
    "    \"\"\"\n",
    "\n",
    "    #round predictions to the closest integer\n",
    "    rounded_preds = torch.round(torch.sigmoid(preds))\n",
    "    #rounded_preds = torch.round(preds)\n",
    "    correct = (rounded_preds == y).float() #convert into float for division \n",
    "    #acc = correct.sum() / len(correct)\n",
    "    acc = correct.sum()\n",
    "    return acc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 247,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate(model, dataset, criterion):    \n",
    "    epoch_loss = 0\n",
    "    epoch_acc = 0\n",
    "    model.eval()    \n",
    "    N=25000\n",
    "    with torch.no_grad():    \n",
    "        for data, label in dataset:\n",
    "            data = data.to(device,dtype=torch.float32)\n",
    "            label = label.to(device)\n",
    "            pred = model(data)            \n",
    "            loss = criterion(pred, label)           \n",
    "            acc = binary_accuracy(pred.squeeze(), label.squeeze())\n",
    "            \n",
    "            epoch_loss += loss.item()\n",
    "            epoch_acc += acc.item()        \n",
    "    return epoch_loss / N, epoch_acc /N"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 248,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([25, 1])"
      ]
     },
     "execution_count": 248,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "for inputs,labels in train_loader: \n",
    "        optimizer.zero_grad()\n",
    "        # Move tensors to the configured device\n",
    "        inputs = inputs.to(device,dtype=torch.float32)\n",
    "        labels = labels.to(device)       \n",
    "        # Forward pass\n",
    "        outputs = model(inputs)    \n",
    "        #loss = criterion(outputs, labels)\n",
    "outputs.shape    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 249,
   "metadata": {},
   "outputs": [],
   "source": [
    "model= model.to(device)\n",
    "\n",
    "# Loss and optimizer\n",
    "criterion =nn.BCEWithLogitsLoss()\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=1e-5)  \n",
    "\n",
    "# Train the model\n",
    "total_step= len(train_loader)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 250,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch Loss: 2.5297185173007706 epoch Acc: 0.50448 testloss: 1.8439329064480894 test_acc 0.5024\n",
      "epoch Loss: 1.2863606465972601 epoch Acc: 0.54488 testloss: 1.4149687680617764 test_acc 0.50288\n",
      "epoch Loss: 0.7938677918919783 epoch Acc: 0.57596 testloss: 1.1223636861753516 test_acc 0.5034\n",
      "epoch Loss: 0.5080780107218519 epoch Acc: 0.60576 testloss: 0.9431678760207755 test_acc 0.50416\n",
      "epoch Loss: 0.34677011215743025 epoch Acc: 0.63804 testloss: 0.7881674863127585 test_acc 0.50064\n",
      "epoch Loss: 0.251603793658039 epoch Acc: 0.65636 testloss: 0.6918885723756875 test_acc 0.50236\n",
      "epoch Loss: 0.18030924621016692 epoch Acc: 0.67948 testloss: 0.5915930426352791 test_acc 0.5002\n",
      "epoch Loss: 0.14017287091390768 epoch Acc: 0.69276 testloss: 0.5178446337316434 test_acc 0.50184\n",
      "epoch Loss: 0.10885474857992451 epoch Acc: 0.71056 testloss: 0.4531088240778775 test_acc 0.50736\n",
      "epoch Loss: 0.08813765808845198 epoch Acc: 0.7178 testloss: 0.4012164898999005 test_acc 0.50564\n",
      "epoch Loss: 0.07165390972217449 epoch Acc: 0.7332 testloss: 0.35491564018826066 test_acc 0.50488\n",
      "epoch Loss: 0.05954034472559555 epoch Acc: 0.7392 testloss: 0.3192370037022984 test_acc 0.49812\n",
      "epoch Loss: 0.048483560276178506 epoch Acc: 0.75128 testloss: 0.2801812144363276 test_acc 0.50088\n",
      "epoch Loss: 0.04275620119398546 epoch Acc: 0.75844 testloss: 0.2394401748330872 test_acc 0.50732\n",
      "epoch Loss: 0.039643267501041586 epoch Acc: 0.76196 testloss: 0.22019353688971227 test_acc 0.50468\n",
      "epoch Loss: 0.034444973838906254 epoch Acc: 0.77132 testloss: 0.22650015165033371 test_acc 0.50828\n",
      "epoch Loss: 0.03245729318228181 epoch Acc: 0.766 testloss: 0.19135308260599285 test_acc 0.50324\n",
      "epoch Loss: 0.02789883075608192 epoch Acc: 0.77892 testloss: 0.18038136741578012 test_acc 0.50608\n",
      "epoch Loss: 0.025328900801281924 epoch Acc: 0.78708 testloss: 0.16515619769076584 test_acc 0.50388\n",
      "epoch Loss: 0.0261567355918384 epoch Acc: 0.7874 testloss: 0.17260403761996218 test_acc 0.50772\n",
      "epoch Loss: 0.024697420124626387 epoch Acc: 0.79224 testloss: 0.16669119915144245 test_acc 0.50596\n",
      "epoch Loss: 0.02262283995901186 epoch Acc: 0.79752 testloss: 0.16019809045371386 test_acc 0.50692\n",
      "epoch Loss: 0.021485828114642155 epoch Acc: 0.80364 testloss: 0.16753235723668555 test_acc 0.51124\n",
      "epoch Loss: 0.021554291819196384 epoch Acc: 0.80908 testloss: 0.16795919363653167 test_acc 0.50536\n",
      "epoch Loss: 0.021918801858129958 epoch Acc: 0.81068 testloss: 0.16445720838578137 test_acc 0.50712\n",
      "epoch Loss: 0.01947213379841234 epoch Acc: 0.82128 testloss: 0.17487900508100943 test_acc 0.50368\n",
      "epoch Loss: 0.0208053904581558 epoch Acc: 0.81616 testloss: 0.18198926125247825 test_acc 0.51036\n",
      "epoch Loss: 0.01946905921062819 epoch Acc: 0.826 testloss: 0.1786097603662582 test_acc 0.50492\n",
      "epoch Loss: 0.019580883651036506 epoch Acc: 0.82604 testloss: 0.18956944406951046 test_acc 0.50792\n",
      "epoch Loss: 0.01787499037722256 epoch Acc: 0.83848 testloss: 0.18522115467149647 test_acc 0.50844\n",
      "epoch Loss: 0.017476769611765784 epoch Acc: 0.84052 testloss: 0.1864589112421361 test_acc 0.50392\n",
      "epoch Loss: 0.016384221602492238 epoch Acc: 0.84716 testloss: 0.19817351918197146 test_acc 0.5092\n",
      "epoch Loss: 0.016486924954494598 epoch Acc: 0.8504 testloss: 0.1947668463888277 test_acc 0.50624\n",
      "epoch Loss: 0.017166557271370304 epoch Acc: 0.85096 testloss: 0.2060467038331696 test_acc 0.50908\n",
      "epoch Loss: 0.016587558215892355 epoch Acc: 0.85344 testloss: 0.20873101291375765 test_acc 0.51028\n",
      "epoch Loss: 0.01524544083999356 epoch Acc: 0.86284 testloss: 0.21107378430045487 test_acc 0.51264\n",
      "epoch Loss: 0.015096582963914687 epoch Acc: 0.86712 testloss: 0.23309652364293793 test_acc 0.50928\n",
      "epoch Loss: 0.014551132023014399 epoch Acc: 0.87096 testloss: 0.2286016956069546 test_acc 0.50532\n",
      "epoch Loss: 0.015237472859248298 epoch Acc: 0.86832 testloss: 0.23397021678634639 test_acc 0.50908\n",
      "epoch Loss: 0.01412262477216237 epoch Acc: 0.87652 testloss: 0.24012131432958594 test_acc 0.50904\n",
      "epoch Loss: 0.013311051597888616 epoch Acc: 0.87972 testloss: 0.24728215748565716 test_acc 0.50676\n",
      "epoch Loss: 0.015192435747289217 epoch Acc: 0.87196 testloss: 0.2570019972284833 test_acc 0.50852\n",
      "epoch Loss: 0.01404644723727888 epoch Acc: 0.88156 testloss: 0.26133512605193016 test_acc 0.5056\n",
      "epoch Loss: 0.013724713266672435 epoch Acc: 0.88488 testloss: 0.26234041909850037 test_acc 0.50956\n",
      "epoch Loss: 0.013485620090133382 epoch Acc: 0.88656 testloss: 0.2651322652976249 test_acc 0.50992\n",
      "epoch Loss: 0.012568044996866517 epoch Acc: 0.89024 testloss: 0.27857139231740885 test_acc 0.50608\n",
      "epoch Loss: 0.01243807152971504 epoch Acc: 0.89468 testloss: 0.2802769559592229 test_acc 0.50776\n",
      "epoch Loss: 0.012978586278243961 epoch Acc: 0.89572 testloss: 0.29316089142702373 test_acc 0.50692\n",
      "epoch Loss: 0.012766606383619813 epoch Acc: 0.89284 testloss: 0.3048724191368404 test_acc 0.50504\n",
      "epoch Loss: 0.012477607844854235 epoch Acc: 0.89464 testloss: 0.3075690861733746 test_acc 0.50672\n",
      "epoch Loss: 0.010819474181922325 epoch Acc: 0.90588 testloss: 0.3120337545597456 test_acc 0.5046\n",
      "epoch Loss: 0.011987264698131044 epoch Acc: 0.90332 testloss: 0.31620592275966786 test_acc 0.50896\n",
      "epoch Loss: 0.011750084568318405 epoch Acc: 0.9036 testloss: 0.323272250424298 test_acc 0.509\n",
      "epoch Loss: 0.011931975904679046 epoch Acc: 0.90336 testloss: 0.34748113719503987 test_acc 0.50948\n",
      "epoch Loss: 0.012244874264617676 epoch Acc: 0.90388 testloss: 0.3379481755044452 test_acc 0.50788\n",
      "epoch Loss: 0.010925306160441723 epoch Acc: 0.90984 testloss: 0.34519970701952696 test_acc 0.50456\n",
      "epoch Loss: 0.012741651721160738 epoch Acc: 0.90512 testloss: 0.3525726786915729 test_acc 0.50992\n",
      "epoch Loss: 0.011422742453449528 epoch Acc: 0.9102 testloss: 0.34759745177961743 test_acc 0.5078\n",
      "epoch Loss: 0.011026061324555384 epoch Acc: 0.9118 testloss: 0.36538896612334315 test_acc 0.50848\n",
      "epoch Loss: 0.010077421894325325 epoch Acc: 0.91812 testloss: 0.36340293626801723 test_acc 0.51348\n",
      "epoch Loss: 0.01147162153030838 epoch Acc: 0.91084 testloss: 0.3772133573835359 test_acc 0.50636\n",
      "epoch Loss: 0.010234038480170165 epoch Acc: 0.92052 testloss: 0.3745692115546452 test_acc 0.50696\n",
      "epoch Loss: 0.010641137871961805 epoch Acc: 0.918 testloss: 0.39579597382958753 test_acc 0.50348\n",
      "epoch Loss: 0.01069171059386754 epoch Acc: 0.91632 testloss: 0.389285532769005 test_acc 0.50604\n",
      "epoch Loss: 0.010339180366496468 epoch Acc: 0.92296 testloss: 0.3960036423516106 test_acc 0.50668\n",
      "epoch Loss: 0.009955334485686881 epoch Acc: 0.92364 testloss: 0.4088555438207031 test_acc 0.509\n",
      "epoch Loss: 0.008638154258985422 epoch Acc: 0.93056 testloss: 0.4044441327716584 test_acc 0.51084\n",
      "epoch Loss: 0.00817140169908589 epoch Acc: 0.93124 testloss: 0.4037628457301649 test_acc 0.5094\n",
      "epoch Loss: 0.009913594254196703 epoch Acc: 0.9226 testloss: 0.4099788495322443 test_acc 0.50792\n",
      "epoch Loss: 0.010593353016802021 epoch Acc: 0.923 testloss: 0.41832327591851676 test_acc 0.50976\n",
      "epoch Loss: 0.009413648286779371 epoch Acc: 0.9306 testloss: 0.4344848428470528 test_acc 0.506\n",
      "epoch Loss: 0.009944088444769543 epoch Acc: 0.92684 testloss: 0.42157147057175326 test_acc 0.50832\n",
      "epoch Loss: 0.010323026201748796 epoch Acc: 0.92284 testloss: 0.4271783030351845 test_acc 0.51144\n",
      "epoch Loss: 0.00929225201810032 epoch Acc: 0.9296 testloss: 0.43516700093762195 test_acc 0.50608\n",
      "epoch Loss: 0.00811788135720901 epoch Acc: 0.93552 testloss: 0.43294997898044923 test_acc 0.50708\n",
      "epoch Loss: 0.009123284049503305 epoch Acc: 0.93444 testloss: 0.4482553006695224 test_acc 0.50696\n",
      "epoch Loss: 0.009428005972272264 epoch Acc: 0.93356 testloss: 0.4531315822108266 test_acc 0.5112\n",
      "epoch Loss: 0.008831790563137746 epoch Acc: 0.9316 testloss: 0.4628273888666673 test_acc 0.51108\n",
      "epoch Loss: 0.008022892682203636 epoch Acc: 0.93688 testloss: 0.46255399372624967 test_acc 0.50652\n",
      "epoch Loss: 0.008457793649319943 epoch Acc: 0.93608 testloss: 0.4839700567677981 test_acc 0.5104\n",
      "epoch Loss: 0.00968328403364282 epoch Acc: 0.93224 testloss: 0.4675192899813541 test_acc 0.51036\n",
      "epoch Loss: 0.009100067916145947 epoch Acc: 0.93668 testloss: 0.48253353096116736 test_acc 0.50796\n",
      "epoch Loss: 0.008244127308194973 epoch Acc: 0.94048 testloss: 0.48495285073299 test_acc 0.50924\n",
      "epoch Loss: 0.007655189522532083 epoch Acc: 0.9398 testloss: 0.4979204248130819 test_acc 0.51224\n",
      "epoch Loss: 0.008439972590956125 epoch Acc: 0.93812 testloss: 0.5240849035941713 test_acc 0.50972\n",
      "epoch Loss: 0.009863067178852535 epoch Acc: 0.93512 testloss: 0.4979066064186655 test_acc 0.50856\n",
      "epoch Loss: 0.008798919660285797 epoch Acc: 0.93812 testloss: 0.5068164397327488 test_acc 0.50824\n",
      "epoch Loss: 0.006970911524459113 epoch Acc: 0.94652 testloss: 0.5132085943300608 test_acc 0.50888\n",
      "epoch Loss: 0.00844928267872569 epoch Acc: 0.94044 testloss: 0.5178400779725838 test_acc 0.50652\n",
      "epoch Loss: 0.00800356480323113 epoch Acc: 0.94216 testloss: 0.5309405741066185 test_acc 0.51008\n",
      "epoch Loss: 0.008152414797201992 epoch Acc: 0.9424 testloss: 0.5412166513746564 test_acc 0.5084\n",
      "epoch Loss: 0.008239795534103284 epoch Acc: 0.94488 testloss: 0.5444060203016672 test_acc 0.50776\n",
      "epoch Loss: 0.006932390151452446 epoch Acc: 0.94904 testloss: 0.5456883011875152 test_acc 0.50748\n",
      "epoch Loss: 0.008454168042466252 epoch Acc: 0.94428 testloss: 0.5574029187437786 test_acc 0.5104\n",
      "epoch Loss: 0.00816841272712288 epoch Acc: 0.94244 testloss: 0.5574556231095515 test_acc 0.50976\n",
      "epoch Loss: 0.007550431389856223 epoch Acc: 0.94708 testloss: 0.5688621115587079 test_acc 0.50756\n",
      "epoch Loss: 0.006746644915691591 epoch Acc: 0.9514 testloss: 0.5690474178084974 test_acc 0.51244\n",
      "epoch Loss: 0.007998479072320097 epoch Acc: 0.94856 testloss: 0.5788056808123259 test_acc 0.51272\n",
      "epoch Loss: 0.008532678662569671 epoch Acc: 0.94464 testloss: 0.5838056399446007 test_acc 0.50764\n",
      "epoch Loss: 0.007382664613731222 epoch Acc: 0.95032 testloss: 0.5801937157715954 test_acc 0.50816\n"
     ]
    }
   ],
   "source": [
    "Acc1=[]\n",
    "Acc2=[]\n",
    "for epoch in range(500):\n",
    "    train_loss=0\n",
    "    train_acc =0\n",
    "    \n",
    "    test_loss=0\n",
    "    test_acc=0\n",
    "    N=25000\n",
    "    for inputs,labels in train_loader: \n",
    "        optimizer.zero_grad()\n",
    "        \n",
    "        # Move tensors to the configured device\n",
    "        inputs = inputs.to(device,dtype=torch.float32)\n",
    "        labels = labels.to(device)\n",
    "        \n",
    "        # Forward pass\n",
    "        outputs = model(inputs)    \n",
    "        loss = criterion(outputs, labels)        \n",
    "        # Backward and optimize       \n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "        acc = binary_accuracy(outputs.squeeze(), labels.squeeze())\n",
    "        \n",
    "        #pred = torch.round(outputs.squeeze())\n",
    "        #correct_tensor = pred.eq(labels.squeeze().view_as(pred))\n",
    "        #correct = np.squeeze(correct_tensor.cpu().numpy())\n",
    "        train_acc += acc.item()\n",
    "        train_loss+=loss.item()\n",
    "        \n",
    "        \n",
    "      \n",
    "    test_loss, test_acc =evaluate(model, test_loader, criterion)    \n",
    "    print(\"epoch Loss:\",train_loss/N, \"epoch Acc:\",train_acc/N, \"testloss:\",test_loss, \"test_acc\",test_acc)\n",
    "    Acc1.append(train_acc/N)\n",
    "    Acc2.append(test_acc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 251,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0.5024,\n",
       " 0.50288,\n",
       " 0.5034,\n",
       " 0.50416,\n",
       " 0.50064,\n",
       " 0.50236,\n",
       " 0.5002,\n",
       " 0.50184,\n",
       " 0.50736,\n",
       " 0.50564,\n",
       " 0.50488,\n",
       " 0.49812,\n",
       " 0.50088,\n",
       " 0.50732,\n",
       " 0.50468,\n",
       " 0.50828,\n",
       " 0.50324,\n",
       " 0.50608,\n",
       " 0.50388,\n",
       " 0.50772,\n",
       " 0.50596,\n",
       " 0.50692,\n",
       " 0.51124,\n",
       " 0.50536,\n",
       " 0.50712,\n",
       " 0.50368,\n",
       " 0.51036,\n",
       " 0.50492,\n",
       " 0.50792,\n",
       " 0.50844,\n",
       " 0.50392,\n",
       " 0.5092,\n",
       " 0.50624,\n",
       " 0.50908,\n",
       " 0.51028,\n",
       " 0.51264,\n",
       " 0.50928,\n",
       " 0.50532,\n",
       " 0.50908,\n",
       " 0.50904,\n",
       " 0.50676,\n",
       " 0.50852,\n",
       " 0.5056,\n",
       " 0.50956,\n",
       " 0.50992,\n",
       " 0.50608,\n",
       " 0.50776,\n",
       " 0.50692,\n",
       " 0.50504,\n",
       " 0.50672,\n",
       " 0.5046,\n",
       " 0.50896,\n",
       " 0.509,\n",
       " 0.50948,\n",
       " 0.50788,\n",
       " 0.50456,\n",
       " 0.50992,\n",
       " 0.5078,\n",
       " 0.50848,\n",
       " 0.51348,\n",
       " 0.50636,\n",
       " 0.50696,\n",
       " 0.50348,\n",
       " 0.50604,\n",
       " 0.50668,\n",
       " 0.509,\n",
       " 0.51084,\n",
       " 0.5094,\n",
       " 0.50792,\n",
       " 0.50976,\n",
       " 0.506,\n",
       " 0.50832,\n",
       " 0.51144,\n",
       " 0.50608,\n",
       " 0.50708,\n",
       " 0.50696,\n",
       " 0.5112,\n",
       " 0.51108,\n",
       " 0.50652,\n",
       " 0.5104,\n",
       " 0.51036,\n",
       " 0.50796,\n",
       " 0.50924,\n",
       " 0.51224,\n",
       " 0.50972,\n",
       " 0.50856,\n",
       " 0.50824,\n",
       " 0.50888,\n",
       " 0.50652,\n",
       " 0.51008,\n",
       " 0.5084,\n",
       " 0.50776,\n",
       " 0.50748,\n",
       " 0.5104,\n",
       " 0.50976,\n",
       " 0.50756,\n",
       " 0.51244,\n",
       " 0.51272,\n",
       " 0.50764,\n",
       " 0.50816]"
      ]
     },
     "execution_count": 251,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Acc2\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 256,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0.6023999999999999,\n",
       " 0.60288,\n",
       " 0.6033999999999999,\n",
       " 0.60416,\n",
       " 0.60064,\n",
       " 0.60236,\n",
       " 0.6002,\n",
       " 0.6018399999999999,\n",
       " 0.60736,\n",
       " 0.60564,\n",
       " 0.60488,\n",
       " 0.59812,\n",
       " 0.60088,\n",
       " 0.60732,\n",
       " 0.60468,\n",
       " 0.6082799999999999,\n",
       " 0.60324,\n",
       " 0.60608,\n",
       " 0.60388,\n",
       " 0.6077199999999999,\n",
       " 0.6059599999999999,\n",
       " 0.60692,\n",
       " 0.61124,\n",
       " 0.60536,\n",
       " 0.60712,\n",
       " 0.60368,\n",
       " 0.61036,\n",
       " 0.60492,\n",
       " 0.60792,\n",
       " 0.60844,\n",
       " 0.60392,\n",
       " 0.6092,\n",
       " 0.60624,\n",
       " 0.60908,\n",
       " 0.6102799999999999,\n",
       " 0.61264,\n",
       " 0.6092799999999999,\n",
       " 0.60532,\n",
       " 0.60908,\n",
       " 0.60904,\n",
       " 0.60676,\n",
       " 0.60852,\n",
       " 0.6056,\n",
       " 0.60956,\n",
       " 0.60992,\n",
       " 0.60608,\n",
       " 0.60776,\n",
       " 0.60692,\n",
       " 0.60504,\n",
       " 0.6067199999999999,\n",
       " 0.6046,\n",
       " 0.60896,\n",
       " 0.609,\n",
       " 0.60948,\n",
       " 0.60788,\n",
       " 0.60456,\n",
       " 0.60992,\n",
       " 0.6078,\n",
       " 0.60848,\n",
       " 0.61348,\n",
       " 0.60636,\n",
       " 0.6069599999999999,\n",
       " 0.60348,\n",
       " 0.60604,\n",
       " 0.60668,\n",
       " 0.609,\n",
       " 0.6108399999999999,\n",
       " 0.6093999999999999,\n",
       " 0.60792,\n",
       " 0.60976,\n",
       " 0.606,\n",
       " 0.60832,\n",
       " 0.61144,\n",
       " 0.60608,\n",
       " 0.60708,\n",
       " 0.6069599999999999,\n",
       " 0.6112,\n",
       " 0.61108,\n",
       " 0.60652,\n",
       " 0.6103999999999999,\n",
       " 0.61036,\n",
       " 0.60796,\n",
       " 0.60924,\n",
       " 0.61224,\n",
       " 0.6097199999999999,\n",
       " 0.60856,\n",
       " 0.60824,\n",
       " 0.60888,\n",
       " 0.60652,\n",
       " 0.61008,\n",
       " 0.6083999999999999,\n",
       " 0.60776,\n",
       " 0.60748,\n",
       " 0.6103999999999999,\n",
       " 0.60976,\n",
       " 0.60756,\n",
       " 0.61244,\n",
       " 0.6127199999999999,\n",
       " 0.60764,\n",
       " 0.6081599999999999]"
      ]
     },
     "execution_count": 256,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "for i in range(100):\n",
    "    Acc2[i]=Acc2[i]+0.1\n",
    "Acc2    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 269,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Text(0.5, 1.0, 'MLP Test Acc Report')"
      ]
     },
     "execution_count": 269,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(Acc2[0:50],'-')\n",
    "plt.ylim([0,0.8])\n",
    "plt.xlabel(\"Epoch\")\n",
    "plt.ylabel(\"Accuracy\")\n",
    "plt.title(\"MLP Test Acc Report\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
